{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb1a433f",
   "metadata": {},
   "source": [
    "## Setting up the packages and relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1063199b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaskLocalRNG()"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using NeuralPDE, Lux, Plots, Random, Distributions, Optim , OptimizationOptimJL\n",
    "using IntegralsCubature, FinancialToolbox\n",
    "using ModelingToolkit: Interval\n",
    "Random.seed!(0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d269da",
   "metadata": {},
   "source": [
    "## Analytical solution function_ Call_pricer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b181d1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "call_pricer (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function call_pricer(x,t)\n",
    "    d1(x,t) = (log(x./K) .+ (r .+ 0.5*σ.^2).*(T-t))./(σ*sqrt(T-t))\n",
    "    d2(x,t) = d1.(x,t) .- σ*sqrt(T-t)\n",
    "    return x.*normcdf.(d1.(x,t)) .- exp(-r*(T-t))*K*normcdf.(d2.(x,t)) \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb1896f",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc283626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "boundary_func (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "σ = 0.2 \n",
    "r = 0.1\n",
    "K = 100 # strike is 100\n",
    "T = 1 #one year \n",
    "Smin = 80\n",
    "Smax = 120 # stock range make it 20% in-the-money and out-the-money\n",
    "#scaling_factor = 1\n",
    "scaling_factor = 0.0555\n",
    "boundary_func(s) = max(s - K,0)*scaling_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ef03d6",
   "metadata": {},
   "source": [
    "## Setting up the PDE for discretization - making it ready for PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c66ca993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Symbolics.VarDomainPairing}:\n",
       " Symbolics.VarDomainPairing(t, 0..1)\n",
       " Symbolics.VarDomainPairing(s, 80..120)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2D PDE in (t, s)\n",
    "@parameters t s\n",
    "@variables U(..)\n",
    "Dt = Differential(t)\n",
    "Ds = Differential(s)\n",
    "Dss = Differential(s)^2\n",
    "\n",
    "eq = Dt(U(t, s)) + r*s*Ds(U(t, s)) + 1/2*σ^2*s^2*Dss(U(t, s)) - r*U(t, s) ~ 0\n",
    "\n",
    "# Boundary Conditions\n",
    "boundary_conditions = [U(T, s) ~ boundary_func(s)]\n",
    "\n",
    "# Problem Domain\n",
    "domains = [t ∈ Interval(0, T), s ∈ Interval(Smin, Smax)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4840d122",
   "metadata": {},
   "source": [
    "## Transforming into optimization problem - ready to be optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5104c2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[38;2;86;182;194mOptimizationProblem\u001b[0m. In-place: \u001b[38;2;86;182;194mtrue\u001b[0m\n",
       "u0: \u001b[0mComponentVector{Float32}(layer_1 = (weight = Float32[-0.5096706 0.42996323; -0.051686242 -0.19706658; … ; -0.23860326 5.093088f-6; 0.5504109 -0.03434386], bias = Float32[0.0; 0.0; … ; 0.0; 0.0;;]), layer_2 = (weight = Float32[0.15251705 0.39284882 … -0.022368534 0.20915501; -0.2943246 0.08905726 … 0.2225429 -0.1315318; … ; -0.42614084 -0.41936278 … -0.3245835 -0.14442606; 0.047960266 0.27465823 … 0.005657302 0.058415208], bias = Float32[0.0; 0.0; … ; 0.0; 0.0;;]), layer_3 = (weight = Float32[0.3952902 0.19821757 … -0.5427456 0.17304797], bias = Float32[0.0;;]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = 2\n",
    "chain = Lux.Chain(Dense(dim, 16, Lux.σ), Dense(16, 16, Lux.σ), Dense(16, 1))\n",
    "ps = Lux.setup(Random.default_rng(), chain)[1]\n",
    "\n",
    "# Transform PDESystem into OptimizationProblem using PINN methodology\n",
    "strategy = QuadratureTraining()\n",
    "discretization_algo = PhysicsInformedNN(chain, strategy, init_params=ps)\n",
    "@named pde_system = PDESystem(eq, boundary_conditions, domains, [t, s], [U(t, s)])\n",
    "optim_prob = discretize(pde_system, discretization_algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f39a8d8",
   "metadata": {},
   "source": [
    "## Getting trial solution - optimal weights of NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0509e570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg\n",
    "Pkg.add(\"TickTock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739807d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "using TickTock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2298c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss is: 4.687473973001896\n",
      "Current loss is: 2.973390552337211\n",
      "Current loss is: 2.7632212951875506\n",
      "Current loss is: 2.7624385008634933\n",
      "Current loss is: 2.7541601325662746\n",
      "Current loss is: 2.74879715278585\n",
      "Current loss is: 2.7433083935079385\n",
      "Current loss is: 2.7200636915466485\n",
      "Current loss is: 2.71429309754764\n",
      "Current loss is: 2.7073394377728657\n",
      "Current loss is: 2.7045727213707544\n",
      "Current loss is: 2.7019920998392637\n",
      "Current loss is: 2.6987228833247663\n",
      "Current loss is: 2.672399451397725\n",
      "Current loss is: 2.632315634352009\n",
      "Current loss is: 2.5553910712120733\n",
      "Current loss is: 2.511773758554655\n",
      "Current loss is: 2.4877773033025536\n",
      "Current loss is: 2.3165185099196983\n",
      "Current loss is: 2.283507735706717\n",
      "Current loss is: 2.0518901952121107\n",
      "Current loss is: 1.9786183905311754\n",
      "Current loss is: 1.9172173836126272\n",
      "Current loss is: 1.8004008630887998\n",
      "Current loss is: 1.7756612747276574\n",
      "Current loss is: 1.7729980330854365\n",
      "Current loss is: 1.521000581381945\n",
      "Current loss is: 1.4027821002382912\n",
      "Current loss is: 1.3738137839703382\n",
      "Current loss is: 1.3737309606695534\n",
      "Current loss is: 1.3351788275195187\n",
      "Current loss is: 1.2747923271542836\n",
      "Current loss is: 1.1385378552350642\n",
      "Current loss is: 0.7799824292497389\n",
      "Current loss is: 0.7416886564944011\n",
      "Current loss is: 0.666827400525857\n",
      "Current loss is: 0.4818750274294481\n",
      "Current loss is: 0.4257610962274856\n",
      "Current loss is: 0.3637362706781275\n",
      "Current loss is: 0.32501160616235714\n",
      "Current loss is: 0.30168765343465004\n",
      "Current loss is: 0.30118858105760904\n",
      "Current loss is: 0.25504017188050265\n",
      "Current loss is: 0.24370361005138397\n",
      "Current loss is: 0.22545885585393957\n",
      "Current loss is: 0.21724764036203364\n",
      "Current loss is: 0.21496700157807624\n",
      "Current loss is: 0.19556588934206012\n",
      "Current loss is: 0.1867724133677264\n",
      "Current loss is: 0.17948475260729788\n",
      "Current loss is: 0.1686018470435517\n",
      "Current loss is: 0.1577971221940617\n",
      "Current loss is: 0.13879081407506852\n",
      "Current loss is: 0.12421894933118703\n",
      "Current loss is: 0.12088887304523413\n",
      "Current loss is: 0.119188102569743\n",
      "Current loss is: 0.1084541792508312\n",
      "Current loss is: 0.10405289826062603\n",
      "Current loss is: 0.10063940637032737\n",
      "Current loss is: 0.10056195319932812\n",
      "Current loss is: 0.10020938462242343\n",
      "Current loss is: 0.09568484323281953\n",
      "Current loss is: 0.08905571168381501\n",
      "Current loss is: 0.08679312072932133\n",
      "Current loss is: 0.08206216898358157\n",
      "Current loss is: 0.08195505074780858\n",
      "Current loss is: 0.07926338420687774\n",
      "Current loss is: 0.07751564846475649\n",
      "Current loss is: 0.07599479261411034\n",
      "Current loss is: 0.07383715941752589\n",
      "Current loss is: 0.07122486278180842\n",
      "Current loss is: 0.06827288031874162\n",
      "Current loss is: 0.06682066186636497\n",
      "Current loss is: 0.06170792739268311\n",
      "Current loss is: 0.06031456346935622\n",
      "Current loss is: 0.06028789115807523\n",
      "Current loss is: 0.05990074496234425\n",
      "Current loss is: 0.057496033275511685\n",
      "Current loss is: 0.05445106136041389\n",
      "Current loss is: 0.05118338476379437\n",
      "Current loss is: 0.046544737876012245\n",
      "Current loss is: 0.04447506749871907\n",
      "Current loss is: 0.04362451903042791\n",
      "Current loss is: 0.0413886472189528\n",
      "Current loss is: 0.03844695613576141\n",
      "Current loss is: 0.03665573347680133\n",
      "Current loss is: 0.035340762691098065\n",
      "Current loss is: 0.03404100378304212\n",
      "Current loss is: 0.03329282516636842\n",
      "Current loss is: 0.032589432011943135\n",
      "Current loss is: 0.03175943847879379\n",
      "Current loss is: 0.030880658731977272\n",
      "Current loss is: 0.03007928035380593\n",
      "Current loss is: 0.02945730365103944\n",
      "Current loss is: 0.02917212407061665\n",
      "Current loss is: 0.028272168865473082\n",
      "Current loss is: 0.027273961119613797\n",
      "Current loss is: 0.026592800294926534\n",
      "Current loss is: 0.02582103030295895\n",
      "Current loss is: 0.025286367909738112\n",
      "Current loss is: 0.025000103691979386\n",
      "Current loss is: 0.024805951828212547\n",
      "Current loss is: 0.024718530123024218\n",
      "Current loss is: 0.02462145359753996\n",
      "Current loss is: 0.024488524328112767\n",
      "Current loss is: 0.024350920241350053\n",
      "Current loss is: 0.024164518323497343\n",
      "Current loss is: 0.02402210882982632\n",
      "Current loss is: 0.023974065197950145\n",
      "Current loss is: 0.023946122735900733\n",
      "Current loss is: 0.023915077659395358\n",
      "Current loss is: 0.023897324575105326\n",
      "Current loss is: 0.023889636958592496\n",
      "Current loss is: 0.02386700409712465\n",
      "Current loss is: 0.02386683986808149\n",
      "Current loss is: 0.023866701524510116\n",
      "Current loss is: 0.02382647012296137\n",
      "Current loss is: 0.023758431672706574\n",
      "Current loss is: 0.02375486813065704\n",
      "Current loss is: 0.023751641021048597\n",
      "Current loss is: 0.023710654099121556\n",
      "Current loss is: 0.023689229750533478\n",
      "Current loss is: 0.023673376244955285\n",
      "Current loss is: 0.0236733941059692\n",
      "Current loss is: 0.023544435301484954\n",
      "Current loss is: 0.023496815247412945\n",
      "Current loss is: 0.02334731533160812\n",
      "Current loss is: 0.023263642415835523\n",
      "Current loss is: 0.023255343932676975\n",
      "Current loss is: 0.023069915035455944\n",
      "Current loss is: 0.02272866224364202\n",
      "Current loss is: 0.022566546770017123\n",
      "Current loss is: 0.02246795646679908\n",
      "Current loss is: 0.022296221609634716\n",
      "Current loss is: 0.022098520532614116\n",
      "Current loss is: 0.022045503254778172\n",
      "Current loss is: 0.022033032199144764\n",
      "Current loss is: 0.02202284267459828\n",
      "Current loss is: 0.021977320373775616\n",
      "Current loss is: 0.021892586557180377\n",
      "Current loss is: 0.02183540796519964\n",
      "Current loss is: 0.021777497101319723\n",
      "Current loss is: 0.021754941507291566\n",
      "Current loss is: 0.021724555694368215\n",
      "Current loss is: 0.021695313484600274\n",
      "Current loss is: 0.02167367866051892\n",
      "Current loss is: 0.02165503104618892\n",
      "Current loss is: 0.021626952322197638\n",
      "Current loss is: 0.021587251306299227\n",
      "Current loss is: 0.02156882979547093\n",
      "Current loss is: 0.021560497880018237\n",
      "Current loss is: 0.021541235977807056\n",
      "Current loss is: 0.02142705031976369\n",
      "Current loss is: 0.02135578897539869\n",
      "Current loss is: 0.02130454934168727\n",
      "Current loss is: 0.021300248658838887\n",
      "Current loss is: 0.021249197513648063\n",
      "Current loss is: 0.02122577455258177\n",
      "Current loss is: 0.021205702369332904\n",
      "Current loss is: 0.021187089137960472\n",
      "Current loss is: 0.021144719194000905\n",
      "Current loss is: 0.02110795995142882\n",
      "Current loss is: 0.02105600392546157\n",
      "Current loss is: 0.020911794912612327\n",
      "Current loss is: 0.02070072505973666\n",
      "Current loss is: 0.020601895861428177\n",
      "Current loss is: 0.020535166569054856\n",
      "Current loss is: 0.02044699116318239\n",
      "Current loss is: 0.020255196209994573\n",
      "Current loss is: 0.020180034124758727\n",
      "Current loss is: 0.01997065464797222\n",
      "Current loss is: 0.019847942934725808\n",
      "Current loss is: 0.019836655105031315\n",
      "Current loss is: 0.019830425191765675\n",
      "Current loss is: 0.019830439011828876\n",
      "Current loss is: 0.019819720394401125\n",
      "Current loss is: 0.019792331270935055\n",
      "Current loss is: 0.01977577565979424\n",
      "Current loss is: 0.019744375799590357\n",
      "Current loss is: 0.01971041281561436\n",
      "Current loss is: 0.019691542122739884\n",
      "Current loss is: 0.019654361082921276\n",
      "Current loss is: 0.019586947359074357\n",
      "Current loss is: 0.01949398795044424\n",
      "Current loss is: 0.01939174182418795\n",
      "Current loss is: 0.0193917336441722\n",
      "Current loss is: 0.01924479330228023\n",
      "Current loss is: 0.01911429409831306\n",
      "Current loss is: 0.01906052918092637\n",
      "Current loss is: 0.018973283794165532\n",
      "Current loss is: 0.018863948546045818\n",
      "Current loss is: 0.018665307264411724\n",
      "Current loss is: 0.018596585730435787\n",
      "Current loss is: 0.01845426760302512\n",
      "Current loss is: 0.018256180917116012\n",
      "Current loss is: 0.01806134229816587\n",
      "Current loss is: 0.017590798796824514\n",
      "Current loss is: 0.017414121421845175\n",
      "Current loss is: 0.017218204108055805\n",
      "Current loss is: 0.017028099214717075\n",
      "Current loss is: 0.01677759730248776\n",
      "Current loss is: 0.016660878298288384\n",
      "Current loss is: 0.01643254002466079\n",
      "Current loss is: 0.01642917304729507\n",
      "Current loss is: 0.016208259410166674\n",
      "Current loss is: 0.016087135377396308\n",
      "Current loss is: 0.016040215637319104\n",
      "Current loss is: 0.016016506284190987\n",
      "Current loss is: 0.016000670427720482\n",
      "Current loss is: 0.01597432831933303\n",
      "Current loss is: 0.01594564969418138\n",
      "Current loss is: 0.015900326052577154\n",
      "Current loss is: 0.01581499915670824\n",
      "Current loss is: 0.015785351402023418\n",
      "Current loss is: 0.015776180162712178\n",
      "Current loss is: 0.015749983346386734\n",
      "Current loss is: 0.01572057857236516\n",
      "Current loss is: 0.015651391603337488\n",
      "Current loss is: 0.015617370680490409\n",
      "Current loss is: 0.015513699715870266\n",
      "Current loss is: 0.015460746512352942\n",
      "Current loss is: 0.015413439846646244\n",
      "Current loss is: 0.015380940194376838\n",
      "Current loss is: 0.015379615421430333\n",
      "Current loss is: 0.015350344481770787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss is: 0.015331731831246012\n",
      "Current loss is: 0.015293642841417751\n",
      "Current loss is: 0.015225274686104125\n",
      "Current loss is: 0.015148347567497063\n",
      "Current loss is: 0.015073357865541797\n",
      "Current loss is: 0.01498902579768249\n",
      "Current loss is: 0.014914213703800496\n",
      "Current loss is: 0.014786239543312435\n",
      "Current loss is: 0.014722919317768061\n",
      "Current loss is: 0.014696539453970738\n",
      "Current loss is: 0.014617521932018547\n",
      "Current loss is: 0.014474157685575854\n",
      "Current loss is: 0.014336593964470885\n",
      "Current loss is: 0.01428005719659107\n",
      "Current loss is: 0.01405615076471131\n",
      "Current loss is: 0.013614106114965541\n",
      "Current loss is: 0.013449115636102483\n",
      "Current loss is: 0.013389023414119103\n",
      "Current loss is: 0.01325615285563769\n",
      "Current loss is: 0.013256156651848011\n",
      "Current loss is: 0.013250964448592903\n",
      "Current loss is: 0.013030736730993617\n",
      "Current loss is: 0.012688680669149664\n",
      "Current loss is: 0.01251090336491696\n",
      "Current loss is: 0.01238659412891578\n",
      "Current loss is: 0.011969441359772612\n",
      "Current loss is: 0.011745023128657453\n",
      "Current loss is: 0.011499214966113268\n",
      "Current loss is: 0.011281723960446823\n",
      "Current loss is: 0.011115792306575358\n",
      "Current loss is: 0.011021830712182126\n",
      "Current loss is: 0.010943807967224956\n",
      "Current loss is: 0.010841055263655976\n",
      "Current loss is: 0.010760168208518498\n",
      "Current loss is: 0.010699899818462278\n",
      "Current loss is: 0.010562937836315971\n",
      "Current loss is: 0.010298318587481954\n",
      "Current loss is: 0.01013751241733761\n",
      "Current loss is: 0.009861625273629562\n",
      "Current loss is: 0.009861603552046551\n",
      "Current loss is: 0.009690829669122193\n",
      "Current loss is: 0.00949197381407659\n",
      "Current loss is: 0.009118751113549636\n",
      "Current loss is: 0.008927057759069029\n",
      "Current loss is: 0.008700368326069241\n",
      "Current loss is: 0.008487106219135988\n",
      "Current loss is: 0.008356105935668786\n",
      "Current loss is: 0.008273163183209805\n",
      "Current loss is: 0.008219656842406352\n",
      "Current loss is: 0.008201823392264808\n",
      "Current loss is: 0.00815667699656112\n",
      "Current loss is: 0.008086665368271644\n",
      "Current loss is: 0.008034976660726832\n",
      "Current loss is: 0.007991586924292863\n",
      "Current loss is: 0.007921141810263\n",
      "Current loss is: 0.007858722399104798\n",
      "Current loss is: 0.007731344579066045\n",
      "Current loss is: 0.0075983637477146735\n",
      "Current loss is: 0.007506138517736096\n",
      "Current loss is: 0.007489726933165525\n",
      "Current loss is: 0.007439561481697488\n",
      "Current loss is: 0.0072064531500473485\n",
      "Current loss is: 0.006925062826384729\n",
      "Current loss is: 0.006765085043577883\n",
      "Current loss is: 0.006328365558313199\n",
      "Current loss is: 0.006095645146892867\n",
      "Current loss is: 0.00584767892830037\n",
      "Current loss is: 0.005767952162000327\n",
      "Current loss is: 0.00567322200521541\n",
      "Current loss is: 0.005510624864536466\n",
      "Current loss is: 0.005500156974820614\n",
      "Current loss is: 0.005499561465690431\n",
      "Current loss is: 0.005499563720269065\n",
      "Current loss is: 0.005486570330578072\n",
      "Current loss is: 0.005459303548204882\n",
      "Current loss is: 0.005440751443733714\n",
      "Current loss is: 0.005426854439838749\n",
      "Current loss is: 0.005404540552634996\n",
      "Current loss is: 0.005392465936244243\n",
      "Current loss is: 0.005324552482120165\n",
      "Current loss is: 0.005229320957148175\n",
      "Current loss is: 0.005066781885089749\n",
      "Current loss is: 0.004990253725047712\n",
      "Current loss is: 0.0048257397404263\n",
      "Current loss is: 0.004800504636567931\n",
      "Current loss is: 0.004668066890652382\n",
      "Current loss is: 0.004559837817475151\n",
      "Current loss is: 0.004428765223443407\n",
      "Current loss is: 0.004360558416668078\n",
      "Current loss is: 0.004325781635238867\n",
      "Current loss is: 0.004310250442280605\n",
      "Current loss is: 0.00428946473410267\n",
      "Current loss is: 0.004254590279519955\n",
      "Current loss is: 0.004184305036843763\n",
      "Current loss is: 0.004135526587118372\n",
      "Current loss is: 0.0041089691470221805\n",
      "Current loss is: 0.004092385381101059\n",
      "Current loss is: 0.0040781096168329405\n",
      "Current loss is: 0.00406861001061645\n",
      "Current loss is: 0.004033029375109018\n",
      "Current loss is: 0.003983959846401668\n",
      "Current loss is: 0.0039688115199292525\n",
      "Current loss is: 0.0039508580570143705\n",
      "Current loss is: 0.003928032625017765\n",
      "Current loss is: 0.0039044812303563586\n",
      "Current loss is: 0.0039043879152235463\n",
      "Current loss is: 0.0038846955283868448\n",
      "Current loss is: 0.0038633670202609127\n",
      "Current loss is: 0.0038411648928143925\n",
      "Current loss is: 0.0038014689823103946\n",
      "Current loss is: 0.0037993390205698562\n",
      "Current loss is: 0.0037952861568463425\n",
      "Current loss is: 0.0037908868877215944\n",
      "Current loss is: 0.0037724002255638957\n",
      "Current loss is: 0.0037496605133532828\n",
      "Current loss is: 0.0037334000939698176\n",
      "Current loss is: 0.0036953668233575977\n",
      "Current loss is: 0.003657211673188522\n",
      "Current loss is: 0.0036487742958284317\n",
      "Current loss is: 0.0036172667606886926\n",
      "Current loss is: 0.0035356780653030373\n",
      "Current loss is: 0.0034851078790035664\n",
      "Current loss is: 0.003463837207487147\n",
      "Current loss is: 0.003436468054697568\n",
      "Current loss is: 0.0034160669736111563\n",
      "Current loss is: 0.0034026647299101676\n",
      "Current loss is: 0.003380104115794962\n",
      "Current loss is: 0.0033711241948852348\n",
      "Current loss is: 0.003367455370433632\n",
      "Current loss is: 0.003354946714296147\n",
      "Current loss is: 0.0033487878376690997\n",
      "Current loss is: 0.003345496721277837\n",
      "Current loss is: 0.0033420798475784154\n",
      "Current loss is: 0.00333569144263685\n",
      "Current loss is: 0.003331057417456278\n",
      "Current loss is: 0.003327531598629334\n",
      "Current loss is: 0.003322209651281884\n",
      "Current loss is: 0.003321890290551738\n",
      "Current loss is: 0.0033216559672639904\n",
      "Current loss is: 0.0033216554663171804\n",
      "Current loss is: 0.003319121909541316\n",
      "Current loss is: 0.003312764643793797\n",
      "Current loss is: 0.0033010729969487336\n",
      "Current loss is: 0.003290919822944259\n",
      "Current loss is: 0.0032773454861080953\n",
      "Current loss is: 0.003263906622066634\n",
      "Current loss is: 0.0032608077687069853\n",
      "Current loss is: 0.0032572028665852036\n",
      "Current loss is: 0.0032383922691116766\n",
      "Current loss is: 0.0032318423853214076\n",
      "Current loss is: 0.00323041060395134\n",
      "Current loss is: 0.0032266883136796956\n",
      "Current loss is: 0.0032223422528932307\n",
      "Current loss is: 0.0032067538445057528\n",
      "Current loss is: 0.0031855025150294173\n",
      "Current loss is: 0.0031642163110050937\n",
      "Current loss is: 0.003140936120928603\n",
      "Current loss is: 0.0031172073934662347\n",
      "Current loss is: 0.0031098631688925432\n",
      "Current loss is: 0.003099311831371886\n",
      "Current loss is: 0.0030887534966085395\n",
      "Current loss is: 0.003074432301974694\n",
      "Current loss is: 0.0030693546645767953\n",
      "Current loss is: 0.0030601345826027125\n",
      "Current loss is: 0.003057377140188262\n",
      "Current loss is: 0.003031670243929753\n",
      "Current loss is: 0.003007521383365791\n",
      "Current loss is: 0.0029978476965015098\n",
      "Current loss is: 0.0029921109832087515\n",
      "Current loss is: 0.002992068897438763\n",
      "Current loss is: 0.0029875156482139613\n",
      "Current loss is: 0.0029836544514761946\n",
      "Current loss is: 0.0029780153591149844\n",
      "Current loss is: 0.0029738725040835646\n",
      "Current loss is: 0.0029726573933432543\n",
      "Current loss is: 0.002971164913949187\n",
      "Current loss is: 0.002968603793629051\n",
      "Current loss is: 0.002965688346286065\n",
      "Current loss is: 0.002964282267022385\n",
      "Current loss is: 0.0029621948141730597\n",
      "Current loss is: 0.0029607460441103467\n",
      "Current loss is: 0.0029586259337042184\n",
      "Current loss is: 0.0029543266761278566\n",
      "Current loss is: 0.002953089276962276\n",
      "Current loss is: 0.002949575481993059\n",
      "Current loss is: 0.0029461450427257785\n",
      "Current loss is: 0.002939349064178764\n",
      "Current loss is: 0.0029343443692813865\n",
      "Current loss is: 0.002933901732980099\n",
      "Current loss is: 0.002931961304955995\n",
      "Current loss is: 0.00292684650631495\n",
      "Current loss is: 0.002923180615154847\n",
      "Current loss is: 0.0029119651532086045\n",
      "Current loss is: 0.002908886667127862\n",
      "Current loss is: 0.0028964379382211344\n",
      "Current loss is: 0.002878884472706977\n",
      "Current loss is: 0.002873620608259363\n",
      "Current loss is: 0.002867247283193993\n",
      "Current loss is: 0.0028621389627990993\n",
      "Current loss is: 0.0028594027385561815\n",
      "Current loss is: 0.0028591769683278846\n",
      "Current loss is: 0.0028546534241499916\n",
      "Current loss is: 0.0028519326163382276\n",
      "Current loss is: 0.0028514290654219347\n",
      "Current loss is: 0.002851269807544943\n",
      "Current loss is: 0.0028483995311477475\n",
      "Current loss is: 0.002845353095600851\n",
      "Current loss is: 0.0028430373463381527\n",
      "Current loss is: 0.0028364541581286937\n",
      "Current loss is: 0.002836123766923236\n",
      "Current loss is: 0.0028304614785765077\n",
      "Current loss is: 0.0028222029478772587\n",
      "Current loss is: 0.0028184831749141137\n",
      "Current loss is: 0.002811509811216363\n",
      "Current loss is: 0.0028051431021518173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss is: 0.0028051454528943104\n",
      "Current loss is: 0.0028048632462473397\n",
      "Current loss is: 0.0028048645793580474\n",
      "Current loss is: 0.0028023976142055687\n",
      "Current loss is: 0.00280107928456894\n",
      "Current loss is: 0.00280062310585446\n",
      "Current loss is: 0.0028006229221644845\n",
      "Current loss is: 0.0027988402961488627\n",
      "Current loss is: 0.002796982429465349\n",
      "Current loss is: 0.0027950139758835574\n",
      "Current loss is: 0.002791569871350946\n",
      "Current loss is: 0.0027882248439960807\n",
      "Current loss is: 0.0027860519659933724\n",
      "Current loss is: 0.0027835051590213004\n",
      "Current loss is: 0.0027822772350974546\n",
      "Current loss is: 0.0027814646444665374\n",
      "Current loss is: 0.0027780244482172663\n",
      "Current loss is: 0.0027751534513184187\n",
      "Current loss is: 0.0027741676508085543\n",
      "Current loss is: 0.002771784468620187\n",
      "Current loss is: 0.0027679350921830095\n",
      "Current loss is: 0.0027671156406160044\n",
      "Current loss is: 0.0027667650088415018\n",
      "Current loss is: 0.002764352195403402\n",
      "Current loss is: 0.002761966799056527\n",
      "Current loss is: 0.00276161804647842\n",
      "Current loss is: 0.0027553574603663227\n",
      "Current loss is: 0.002755241706492942\n",
      "Current loss is: 0.0027478872949310068\n",
      "Current loss is: 0.0027472580431507007\n",
      "Current loss is: 0.002746216691283164\n",
      "Current loss is: 0.0027449178969465716\n",
      "Current loss is: 0.002743737430208745\n",
      "Current loss is: 0.002742690935078422\n",
      "Current loss is: 0.0027425457295759156\n",
      "Current loss is: 0.0027419510239086705\n",
      "Current loss is: 0.0027413549070577628\n",
      "Current loss is: 0.002741168480549791\n",
      "Current loss is: 0.002741170459258667\n",
      "Current loss is: 0.0027408747065314843\n",
      "Current loss is: 0.002739484019778648\n",
      "Current loss is: 0.002739105726554147\n",
      "Current loss is: 0.002738949392700704\n",
      "Current loss is: 0.002738719374649518\n",
      "Current loss is: 0.002738574405987298\n",
      "Current loss is: 0.002738517884545385\n",
      "Current loss is: 0.002738519053318561\n",
      "Current loss is: 0.0027385128436465647\n",
      "Current loss is: 0.0027384299613364676\n",
      "Current loss is: 0.002738409020067654\n",
      "Current loss is: 0.002738407742872212\n",
      "Current loss is: 0.002738395210014288\n",
      "Current loss is: 0.0027382437434407287\n",
      "Current loss is: 0.0027382382888039443\n",
      "Current loss is: 0.0027381157943899477\n",
      "Current loss is: 0.002738090234171831\n",
      "Current loss is: 0.0027373950625856442\n",
      "Current loss is: 0.0027373458585100846\n",
      "Current loss is: 0.0027372314724132115\n",
      "Current loss is: 0.002737230021666859\n",
      "Current loss is: 0.0027372198263235416\n",
      "Current loss is: 0.0027371770823088177\n",
      "Current loss is: 0.0027368568849937503\n",
      "Current loss is: 0.0027365383170033486\n",
      "Current loss is: 0.002736195080134966\n",
      "Current loss is: 0.002734539215513719\n",
      "Current loss is: 0.0027322200087491924\n",
      "Current loss is: 0.0027314409953846873\n",
      "Current loss is: 0.0027283345424350116\n",
      "Current loss is: 0.002726183358078711\n",
      "Current loss is: 0.0027242854805255663\n",
      "Current loss is: 0.002723493343504038\n",
      "Current loss is: 0.002722104450341318\n",
      "Current loss is: 0.0027215813131796114\n",
      "Current loss is: 0.002721564045752004\n",
      "Current loss is: 0.002719896402759623\n",
      "Current loss is: 0.002715764915845186\n",
      "Current loss is: 0.0027098381522048113\n",
      "Current loss is: 0.0027076720346689118\n",
      "Current loss is: 0.002703493118739181\n",
      "Current loss is: 0.0026997589153670456\n",
      "Current loss is: 0.002695721751782468\n",
      "Current loss is: 0.002688716940183105\n",
      "Current loss is: 0.002682560710275185\n",
      "Current loss is: 0.0026808302143562926\n",
      "Current loss is: 0.0026746953222771016\n",
      "Current loss is: 0.0026725121370055273\n",
      "Current loss is: 0.0026654885336901252\n",
      "Current loss is: 0.002659278025842991\n",
      "Current loss is: 0.002657731715109781\n",
      "Current loss is: 0.0026568911225539793\n",
      "Current loss is: 0.00265493593359947\n",
      "Current loss is: 0.002650561279521061\n",
      "Current loss is: 0.0026486250795645064\n",
      "Current loss is: 0.002644507324192086\n",
      "Current loss is: 0.002641448650057163\n",
      "Current loss is: 0.00263493641661116\n",
      "Current loss is: 0.0026240256064601498\n",
      "Current loss is: 0.002619664132329717\n",
      "Current loss is: 0.0026140849069578634\n",
      "Current loss is: 0.00260873784683914\n",
      "Current loss is: 0.0026004599595812116\n",
      "Current loss is: 0.0025922810140963596\n",
      "Current loss is: 0.0025820847164325315\n",
      "Current loss is: 0.0025739147711832727\n",
      "Current loss is: 0.002569819098872203\n",
      "Current loss is: 0.0025648421512714523\n",
      "Current loss is: 0.0025623191275308895\n",
      "Current loss is: 0.0025584094800611148\n",
      "Current loss is: 0.0025547708765334305\n",
      "Current loss is: 0.002553167840682213\n",
      "Current loss is: 0.0025522464500914877\n",
      "Current loss is: 0.0025430553218922106\n",
      "Current loss is: 0.00253097629242938\n",
      "Current loss is: 0.002524451536117718\n",
      "Current loss is: 0.002522594679748637\n",
      "Current loss is: 0.002522587030544793\n",
      "Current loss is: 0.0025209741988064353\n",
      "Current loss is: 0.0025209724322124\n",
      "Current loss is: 0.002509928167217631\n",
      "Current loss is: 0.0025022305435481013\n",
      "Current loss is: 0.0024976876430764373\n",
      "Current loss is: 0.0024957864399860114\n",
      "Current loss is: 0.002492488708892996\n",
      "Current loss is: 0.0024860216924495024\n",
      "Current loss is: 0.0024767603589748504\n",
      "Current loss is: 0.002471385160875351\n",
      "Current loss is: 0.002469193259313076\n",
      "Current loss is: 0.002466334826707554\n",
      "Current loss is: 0.002459097747483915\n",
      "Current loss is: 0.0024480391020928246\n",
      "Current loss is: 0.002441357855583581\n",
      "Current loss is: 0.002437858719709755\n",
      "Current loss is: 0.0024347059110604793\n",
      "Current loss is: 0.00243466509608543\n",
      "Current loss is: 0.0024329378048549436\n",
      "Current loss is: 0.0024309265108526323\n",
      "Current loss is: 0.0024304259496072296\n",
      "Current loss is: 0.002427114240075775\n",
      "Current loss is: 0.0024252161407336188\n",
      "Current loss is: 0.002420556689088521\n",
      "Current loss is: 0.002411555811477863\n",
      "Current loss is: 0.002402693451935582\n",
      "Current loss is: 0.002393942273726333\n",
      "Current loss is: 0.002389548803646728\n",
      "Current loss is: 0.0023895283889010894\n",
      "Current loss is: 0.002373985384494371\n",
      "Current loss is: 0.002364474355563871\n",
      "Current loss is: 0.0023615272234667945\n",
      "Current loss is: 0.002357738189281747\n",
      "Current loss is: 0.0023534758236401156\n",
      "Current loss is: 0.002350940086429584\n",
      "Current loss is: 0.00235094173665151\n",
      "Current loss is: 0.0023494923324580267\n",
      "Current loss is: 0.0023489815163901823\n",
      "Current loss is: 0.002348609998056964\n",
      "Current loss is: 0.0023480999253956193\n",
      "Current loss is: 0.002346046992971802\n",
      "Current loss is: 0.0023452266914981744\n",
      "Current loss is: 0.0023440829627329315\n",
      "Current loss is: 0.0023384427425749608\n",
      "Current loss is: 0.002323293797835815\n",
      "Current loss is: 0.002316567520517777\n",
      "Current loss is: 0.0023085123337494473\n",
      "Current loss is: 0.002303279473734786\n",
      "Current loss is: 0.002298319844840657\n",
      "Current loss is: 0.0022923690414070044\n",
      "Current loss is: 0.002290445173247042\n",
      "Current loss is: 0.002289669024443493\n",
      "Current loss is: 0.002289315376807994\n",
      "Current loss is: 0.0022888956015954596\n",
      "Current loss is: 0.0022885082524124415\n",
      "Current loss is: 0.0022872742364065733\n",
      "Current loss is: 0.0022867567056211427\n",
      "Current loss is: 0.002286536915102226\n",
      "Current loss is: 0.002286233540279226\n",
      "Current loss is: 0.0022857584905699698\n",
      "Current loss is: 0.0022851472108284983\n",
      "Current loss is: 0.0022845925795950722\n",
      "Current loss is: 0.0022837932836453348\n",
      "Current loss is: 0.0022837790154446253\n",
      "Current loss is: 0.002283135257379686\n",
      "Current loss is: 0.0022820052557893026\n",
      "Current loss is: 0.002281176486296031\n",
      "Current loss is: 0.0022803461577671105\n",
      "Current loss is: 0.002279631750649989\n",
      "Current loss is: 0.0022786839531246336\n",
      "Current loss is: 0.0022785298244611006\n",
      "Current loss is: 0.0022781372402346832\n",
      "Current loss is: 0.002276097462603822\n",
      "Current loss is: 0.002274148293074695\n",
      "Current loss is: 0.0022734805825858962\n",
      "Current loss is: 0.002272561793221145\n",
      "Current loss is: 0.0022722309392846523\n",
      "Current loss is: 0.00227148609236338\n",
      "Current loss is: 0.002270645662736808\n",
      "Current loss is: 0.002269311189763671\n",
      "Current loss is: 0.002267391930187004\n",
      "Current loss is: 0.00226677306897723\n",
      "Current loss is: 0.002266722240282008\n",
      "Current loss is: 0.0022649084026347952\n",
      "Current loss is: 0.002262472312173104\n",
      "Current loss is: 0.002260944055395807\n",
      "Current loss is: 0.0022606870300344575\n",
      "Current loss is: 0.002260652212152706\n",
      "Current loss is: 0.0022606229773190433\n",
      "Current loss is: 0.0022606241877737624\n",
      "Current loss is: 0.0022606121268467358\n",
      "Current loss is: 0.0022605891910181517\n",
      "Current loss is: 0.0022605903540161066\n",
      "Current loss is: 0.0022605896792311144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralPDE.Phi{Chain{NamedTuple{(:layer_1, :layer_2, :layer_3), Tuple{Dense{true, typeof(NNlib.sigmoid_fast), typeof(Lux.glorot_uniform), typeof(Lux.zeros32)}, Dense{true, typeof(NNlib.sigmoid_fast), typeof(Lux.glorot_uniform), typeof(Lux.zeros32)}, Dense{true, typeof(identity), typeof(Lux.glorot_uniform), typeof(Lux.zeros32)}}}}, NamedTuple{(:layer_1, :layer_2, :layer_3), Tuple{NamedTuple{(), Tuple{}}, NamedTuple{(), Tuple{}}, NamedTuple{(), Tuple{}}}}}(Chain(), (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = NamedTuple()))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tick()\n",
    "callback = function (p,l)\n",
    "    println(\"Current loss is: $l\")\n",
    "    return false\n",
    "end\n",
    "\n",
    "opt = BFGS()\n",
    "result = Optimization.solve(optim_prob, opt, callback = callback, maxiters=2500, reltol=1e-6)\n",
    "result.original\n",
    "phi = discretization_algo.phi\n",
    "#tock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf321bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = 0.5\n",
    "x_domain = Smin:dx:Smax\n",
    "S_domain = collect(x_domain)\n",
    "\n",
    "times = [0, 0.25, 0.5, 1]\n",
    "#plots = Array{Plots.Plot{Plots.GRBackend},1}()\n",
    "\n",
    "\n",
    "u_predict1 = [phi([times[1], current_x],result.u) for current_x in x_domain]\n",
    "u_predict1 = reduce(vcat, u_predict1)/scaling_factor\n",
    "u_true1 = call_pricer(S_domain, times[1])\n",
    "\n",
    "u_predict2 = [phi([times[2], current_x],result.u) for current_x in x_domain]\n",
    "u_predict2 = reduce(vcat, u_predict2)/scaling_factor\n",
    "u_true2 = call_pricer(S_domain, times[2])\n",
    "\n",
    "u_predict3 = [phi([times[3], current_x],result.u) for current_x in x_domain]\n",
    "u_predict3 = reduce(vcat, u_predict3)/scaling_factor\n",
    "u_true3 = call_pricer(S_domain, times[3])\n",
    "\n",
    "u_predict4 = [phi([times[4], current_x],result.u) for current_x in x_domain]\n",
    "u_predict4 = reduce(vcat, u_predict4)/scaling_factor\n",
    "u_true4 = max.(S_domain .- K, 0)\n",
    "\n",
    "#for i in 1:length(times)\n",
    "    #current_t = times[i]\n",
    "    #u_predict = [phi([current_t, current_x],result.u) for current_x in x_domain]\n",
    "    #u_predict = reduce(vcat, u_predict)/scaling_factor\n",
    "    #u_predict = max.(u_predict,0)\n",
    "    #u_true = call_pricer(S_domain, current_t)\n",
    "    #push!(plots, plot(S_domain, [u_true, u_predict], label= [\"Analytical\" \"PINN\"], title=\"t = $(current_t)\",legend=:topleft,\n",
    "            #xlabel = \"Stock prices\", ylabel = \"Option prices\", grid=:false,framestyle = :box, widen=:false))\n",
    "    \n",
    "#end\n",
    "\n",
    "#plot(plots[1], plots[2], plots[3], plots[4], layout = 4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee937471",
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot\n",
    "using Makie # to enable save function \n",
    "\n",
    "#figure(1);\n",
    "fig = figure(figsize=(10, 10), dpi=1200);\n",
    "#subplots_adjust(hspace=0.5,wspace=0.9)\n",
    "\n",
    "#subplot(221) ;  PyPlot.plot(x_domain,u_predict1,color = \"blue\",label = \"PINN\"); PyPlot.plot(x_domain,u_true1,color = \"magenta\", label = \"Analytical\");\n",
    "#PyPlot.title(\"Time = 0\",fontweight=\"bold\") ; xlabel(\"S\") ; ylabel(\"Call prices\")\n",
    "#; PyPlot.legend(loc=\"upper left\")\n",
    "\n",
    "#subplot(222) ;  PyPlot.plot(x_domain,u_predict4,color = \"blue\",label = \"PINN\"); PyPlot.plot(x_domain,u_true4,color = \"magenta\", label = \"Analytical\");\n",
    "#PyPlot.title(\"Time = 1\",fontweight=\"bold\") ; xlabel(\"S\") ; ylabel(\"Call prices\")\n",
    "#; PyPlot.legend(loc=\"upper left\")\n",
    "\n",
    "subplot(221) ;  PyPlot.plot(x_domain,u_predict1,color = \"blue\",label = \"PINN\"); PyPlot.plot(x_domain,u_true1,color = \"magenta\", label = \"Analytical\");\n",
    "PyPlot.title(\"Time = 0\",fontweight=\"bold\") ; xlabel(\"S\") ; ylabel(\"Call prices\")\n",
    "; PyPlot.legend(loc=\"upper left\")\n",
    "\n",
    "subplot(222) ;  PyPlot.plot(x_domain,u_predict2,color = \"blue\",label = \"PINN\"); PyPlot.plot(x_domain,u_true2,color = \"magenta\", label = \"Analytical\");\n",
    "PyPlot.title(\"Time = 0.25\",fontweight=\"bold\") ; xlabel(\"S\") ; ylabel(\"Call prices\")\n",
    "; PyPlot.legend(loc=\"upper left\")\n",
    "\n",
    "subplot(223) ;  PyPlot.plot(x_domain,u_predict3,color = \"blue\",label = \"PINN\"); PyPlot.plot(x_domain,u_true3,color = \"magenta\", label = \"Analytical\");\n",
    "PyPlot.title(\"Time = 0.5\",fontweight=\"bold\") ; xlabel(\"S\") ; ylabel(\"Call prices\")\n",
    "; PyPlot.legend(loc=\"upper left\")\n",
    "\n",
    "subplot(224) ;  PyPlot.plot(x_domain,u_predict4,color = \"blue\",label = \"PINN\"); PyPlot.plot(x_domain,u_true4,color = \"magenta\", label = \"Analytical\");\n",
    "PyPlot.title(\"Time = 1\",fontweight=\"bold\") ; xlabel(\"S\") ; ylabel(\"Call prices\")\n",
    "; PyPlot.legend(loc=\"upper left\")\n",
    "\n",
    "fig\n",
    "save(\"./Fig_21.png\", fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea0088c",
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot\n",
    "\n",
    "#figure(1);\n",
    "fig = figure(figsize=(10, 10), dpi=1200);\n",
    "#subplots_adjust(hspace=0.5,wspace=0.9)\n",
    "subplot(221) ;  PyPlot.plot(x_domain, abs.(u_predict1.- u_true1),color = \"magenta\",label = \"Absolute error\");\n",
    "PyPlot.title(\"Time = 0\",fontweight=\"bold\") ; xlabel(\"S\") ; ylabel(\"Call prices\")\n",
    "; PyPlot.legend(loc=\"upper left\")\n",
    "\n",
    "subplot(222) ;  PyPlot.plot(x_domain, abs.(u_predict2.- u_true2) ,color = \"magenta\",label = \"Absolute error\");\n",
    "PyPlot.title(\"Time = 0.25\",fontweight=\"bold\") ; xlabel(\"S\") ; ylabel(\"Call prices\")\n",
    "; PyPlot.legend(loc=\"upper left\")\n",
    "\n",
    "subplot(223) ;  PyPlot.plot(x_domain, abs.(u_predict3.- u_true3) ,color = \"magenta\",label = \"Absolute error\"); \n",
    "PyPlot.title(\"Time = 0.5\",fontweight=\"bold\") ; xlabel(\"S\") ; ylabel(\"Call prices\")\n",
    "; PyPlot.legend(loc=\"upper left\")\n",
    "\n",
    "subplot(224) ;  PyPlot.plot(x_domain, abs.(u_predict4.- u_true4) ,color = \"magenta\",label = \"Absolute error\"); \n",
    "PyPlot.title(\"Time = 1\",fontweight=\"bold\") ; xlabel(\"S\") ; ylabel(\"Call prices\")\n",
    "; PyPlot.legend(loc=\"upper left\")\n",
    "\n",
    "fig\n",
    "save(\"./Fig_2.png\", fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393049ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bff09449",
   "metadata": {},
   "source": [
    "## Error plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5240520",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "using Plots\n",
    "\n",
    "plots = Array{Plots.Plot{Plots.GRBackend},1}()\n",
    "\n",
    "for i in 1:length(times)\n",
    "    current_t = times[i]\n",
    "    u_predict = [phi([current_t, current_x],result.u) for current_x in S_domain]\n",
    "    u_predict = reduce(vcat, u_predict)/scaling_factor\n",
    "    u_true = call_pricer(S_domain, current_t)\n",
    "    error = abs.(u_true - u_predict)\n",
    "    push!(plots, Plots.plot(S_domain, error, label=:false ,legend=:topleft, title=\"t = $(current_t)\",\n",
    "            xlabel = \"S\", ylabel = \"Absolute error\"))\n",
    "    \n",
    "end\n",
    "\n",
    "Plots.plot(plots[1], plots[2], plots[3], plots[4], layout = 4, framestyle=:box, dpi=150, lw = 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe15aaed",
   "metadata": {},
   "source": [
    "## Calculating vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3606489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "function BS_vol(S0, K, r, T, price)\n",
    "    f(x) = call_pricer(S0,0) - price\n",
    "    vol = find_zero(f, 0.3)\n",
    "    return vol\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76496f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_predict = [phi([0, current_x],result.u) for current_x in S_domain]\n",
    "u_predict = reduce(vcat, u_predict)/scaling_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a91be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BS_vol(S_domain, K, r, T, u_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e0cdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg\n",
    "Pkg.add(\"Roots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3ed2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c76f11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
